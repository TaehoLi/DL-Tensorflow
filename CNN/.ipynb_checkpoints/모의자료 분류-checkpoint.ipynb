{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\my\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-0ff349b20139>:76: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-0ff349b20139>:89: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 1 accuracy= 0.550000\n",
      "Epoch: 2 accuracy= 0.550000\n",
      "Epoch: 3 accuracy= 0.700000\n",
      "Epoch: 4 accuracy= 0.750000\n",
      "Epoch: 5 accuracy= 0.800000\n",
      "Epoch: 6 accuracy= 0.800000\n",
      "Epoch: 7 accuracy= 0.850000\n",
      "Epoch: 8 accuracy= 0.850000\n",
      "Epoch: 9 accuracy= 0.900000\n",
      "Epoch: 10 accuracy= 0.900000\n",
      "Epoch: 11 accuracy= 0.900000\n",
      "Epoch: 12 accuracy= 0.900000\n",
      "Epoch: 13 accuracy= 0.900000\n",
      "Epoch: 14 accuracy= 0.950000\n",
      "Epoch: 15 accuracy= 0.950000\n",
      "Epoch: 16 accuracy= 0.950000\n",
      "Epoch: 17 accuracy= 1.000000\n",
      "Epoch: 18 accuracy= 1.000000\n",
      "Epoch: 19 accuracy= 1.000000\n",
      "Epoch: 20 accuracy= 1.000000\n",
      "misclassification error: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from libs.connections import linear \n",
    "from keras.utils import np_utils \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def linear(x, n_units, scope=None, stddev=0.02,\n",
    "           activation=lambda x: x):\n",
    "    \"\"\"Fully-connected network.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Tensor\n",
    "        Input tensor to the network.\n",
    "    n_units : int\n",
    "        Number of units to connect to.\n",
    "    scope : str, optional\n",
    "        Variable scope to use.\n",
    "    stddev : float, optional\n",
    "        Initialization's standard deviation.\n",
    "    activation : arguments, optional\n",
    "        Function which applies a nonlinearity\n",
    "    Returns\n",
    "    -------\n",
    "    x : Tensor\n",
    "        Fully-connected output.\n",
    "    \"\"\"\n",
    "    shape = x.get_shape().as_list()\n",
    "\n",
    "    with tf.variable_scope(scope or \"Linear\"):\n",
    "        matrix = tf.get_variable(\"Matrix\", [shape[1], n_units], tf.float32,\n",
    "                                 tf.random_normal_initializer(stddev=stddev))\n",
    "        return activation(tf.matmul(x, matrix))\n",
    "\n",
    "\n",
    "# 그래프 리셋\n",
    "tf.reset_default_graph()\n",
    "# 재현성을 위해 시드 지정\n",
    "tf.set_random_seed(1); np.random.seed(1)\n",
    "# true images\n",
    "A=np.array([[0,0,0,0,0,0], [0,1,0,0,0,0],[0,1,1,0,0,0],[0,1,0,1,0,0],[0,1,0,0,1,0],[0,0,0,0,0,0]])\n",
    "B=np.array([[0,0,0,0,0,0], [0,0,0,0,1,0],[0,0,0,0,1,0],[0,0,0,0,1,0],[0,1,1,1,1,0],[0,0,0,0,0,0]])\n",
    "\n",
    "# 훈련 데이터 생성 \n",
    "trainX=np.zeros((20,36))\n",
    "for i in range(10):\n",
    "    trainX[i,:]=A.reshape(1,6*6)\n",
    "    trainX[i+10,:]=B.reshape(1,6*6)\n",
    "train_x=trainX.reshape(720,1)\n",
    "noise=np.random.choice(np.arange(2), 720, replace=True,p=[0.9,0.1])\n",
    "v=np.where(noise>0)\n",
    "train_x[v]=np.abs(train_x[v]-1)\n",
    "trainX=train_x.reshape(20,36)\n",
    "train_y=np.concatenate((np.ones((10,1)),np.zeros((10,1))),axis=0)\n",
    "train_y=np.array(train_y, np.int64)\n",
    "trainY = np_utils.to_categorical(train_y, 2)\n",
    "\n",
    "# 훈련 데이터 이미지\n",
    "f,axes =plt.subplots(figsize=(7,7), nrows=2, ncols=4, sharey=True, sharex=True)\n",
    "for ii in range(8):\n",
    "    plt.subplot(2,4,ii+1); \n",
    "    if ii<4: \n",
    "        if ii==0: plt.imshow(A,cmap='gray', interpolation='none')\n",
    "        else: plt.imshow(trainX[ii,:].reshape(6,6),cmap='gray', interpolation='none')\n",
    "    else: \n",
    "        if ii==4: plt.imshow(B,cmap='gray', interpolation='none')\n",
    "        else: plt.imshow(trainX[ii+5,:].reshape(6,6),cmap='gray', interpolation='none')\n",
    "learning_rate=0.01; epochs=20\n",
    "X=tf.placeholder(tf.float32,[None,36])\n",
    "X_img=tf.reshape(X,[-1,6,6,1]) \n",
    "Y=tf.placeholder(tf.float32,[None,2])\n",
    "# 합성곱에 사용하는 필터 크기와 개수, 보폭 지정\n",
    "K1=tf.Variable(tf.random_normal([4,4,1,4],stddev=0.01))\n",
    "a1=tf.nn.conv2d(X_img, K1, strides=[1,1,1,1], padding='VALID')\n",
    "# 배치정규화 \n",
    "a1=tf.layers.batch_normalization(a1, training=True)\n",
    "# 활성화함수 지정 \n",
    "a1=tf.nn.relu(a1)\n",
    "# 풀링의 종류와 크기, 보폭 지정 \n",
    "h1=tf.nn.max_pool(a1,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "# 합성층의 마지막 부분을 1D로 변환\n",
    "Flat=tf.reshape(h1,[-1,np.prod(h1.get_shape().as_list()[1:4])])\n",
    "# 완전 연결 신경망의 은닉층의 구조 지정\n",
    "W1=tf.get_variable(\"W1\",shape=[np.prod(h1.get_shape().as_list()[1:4]),10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1=tf.Variable(tf.random_normal([10]))\n",
    "L1=tf.matmul(Flat, W1)+b1\n",
    "# 최종 출력을 위해 소프트맥스함수 지정\n",
    "pred =linear(L1, 2, activation=tf.nn.softmax)\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
    "optim=tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "correct_predict=tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "# 정분류율\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "sess=tf.Session(); sess.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):\n",
    "    sess.run(optim, feed_dict={X:trainX, Y:trainY})\n",
    "    acc=sess.run(accuracy, feed_dict={X:trainX, Y:trainY})\n",
    "    print('Epoch: %d' %(epoch+1),'accuracy= %f' %(acc))\n",
    "# 오분류율 \n",
    "print('misclassification error:', 1-sess.run(accuracy, feed_dict={X:trainX, Y: trainY}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
